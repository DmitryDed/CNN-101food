## Лабораторная работа #3.
## Изучение влияние параметра “темп обучения” на процесс обучения нейронной сети на примере решения задачи классификации Food-101 с использованием техники обучения Transfer Learning
## 1. С использованием и техники обучения Transfer Learning обучить нейронную сеть EfficientNet-B0 (предварительно обученную на базе изображений imagenet) для решения задачи классификации изображений Food-101 с использованием фиксированных темпов обучения 0.01, 0.001, 0.0001.
 

## Графики
![image](https://user-images.githubusercontent.com/81873177/116250303-46c18800-a776-11eb-8407-f5c1215895b5.png)


## 2. Реализовать и применить в обучении следующие политики изменения темпа обучения, а также определить оптимальные параметры для каждой политики:
## a. Косинусное затухание (Cosine Decay) 
```python
tf.keras.experimental.CosineDecay(initial_learning_rate, decay_steps, alpha=0.0)
```
initial_learning_rate	- начальная скорость обучения
decay_steps	- количество шагов
alpha -	минимальное значение скорости обучения

## Графики
![image](https://user-images.githubusercontent.com/81873177/116254807-55aa3980-a77a-11eb-8246-d9b70013396e.png)



## b. Косинусное затухание с перезапусками (Cosine Decay with Restarts) 


## Анализ результатов:
1. Исследуя графики метрики точности и графики функции потерь, можно прийти к выводу, что в нашем случае шаг 0,0001 является оптимальным, так как на графике метрики точности наблюдаются наивысшие значения - 68%, а на графике функции потерь наименьшие - 1,... .
2. 
